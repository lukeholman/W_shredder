---
title: "Code to run the model on all parameter spaces using SLURM job manager"
author: "Luke Holman"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

```{r setting_wd, eval=FALSE}
# This bit is for the unimelb cluster, Spartan
working_directory <- "/data/projects/punim0243/W_shredder"
setwd(working_directory)
```


```{r results='hide', message=FALSE, warning=FALSE}
source_rmd <- function(file){
  options(knitr.duplicate.label = "allow")
  tempR <- tempfile(tmpdir = ".", fileext = ".R")   # sdfgh
  on.exit(unlink(tempR))
  knitr::purl(file, output = tempR, quiet = TRUE)
  source(tempR, local = globalenv())
}
source_rmd("analysis/model_functions.Rmd")
custom_functions <- ls()
```


## Define the parameter space still not yet run
This is defined in an R script that sets up the parameter space, and runs everything that has not already completed.
```{r eval=FALSE}
print("About to set up parameters")
source("code/set_up_parameters.R")
```


## Now launch lots of SLURM jobs to run the remaining parameter spaces
```{r eval=FALSE}
chunk_size <- 4000
cpus <- 1 # 1 CPU per node (i.e. parallelise jobs, but each job uses only one CPU)
sopt <- list(time = '168:00:00',  # max run time per node in hours
             mem  = '32768')      # 32GB memory per node

chunks <- split(1:nrow(parameters),
                ceiling(seq_along(1:nrow(parameters))/chunk_size))
number_of_chunks <- length(chunks)


sjob <- slurm_apply(
  f = function(i) {
    try(do_all_parameters(parameters[chunks[[i]],], 
                          over_write = FALSE, 
                          cores = cpus,
                          wd = working_directory))
  },
  params = data.frame(i = 1:length(chunks)),
  add_objects = c("do_all_parameters", 
                  "parameters", "cpus",
                  "working_directory",
                  "chunks", "number_of_chunks",
                  custom_functions),
  jobname = 'W_shredder',
  nodes = number_of_chunks, 
  cpus_per_node = cpus, 
  slurm_options = sopt)
```

